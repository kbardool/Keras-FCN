{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from keras.optimizers import SGD, Adam, Nadam\n",
    "from keras.callbacks import *\n",
    "from keras.objectives import *\n",
    "from keras.metrics import binary_accuracy\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "#import keras.utils.visualize_util as vis_util\n",
    "\n",
    "from models import *\n",
    "from utils.loss_function import *\n",
    "from utils.metrics import *\n",
    "from utils.SegDataGenerator import *\n",
    "# from .train import train\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size, epochs, lr_base, lr_power, weight_decay, classes,\n",
    "          model_name, train_file_path, val_file_path,\n",
    "          data_dir, label_dir, target_size=None, batchnorm_momentum=0.9,\n",
    "          resume_training=False, class_weight=None, dataset='VOC2012',\n",
    "          loss_fn=softmax_sparse_crossentropy_ignoring_last_label,\n",
    "          metrics=[sparse_accuracy_ignoring_last_label],\n",
    "          loss_shape=None,\n",
    "          label_suffix='.png',\n",
    "          data_suffix='.jpg',\n",
    "          ignore_label=255,\n",
    "          label_cval=255):\n",
    "    \n",
    "    \n",
    "    if target_size:\n",
    "        input_shape = target_size + (3,)\n",
    "    else:\n",
    "        input_shape = (None, None, 3)\n",
    "    batch_shape = (batch_size,) + input_shape\n",
    "\n",
    "    ###########################################################\n",
    "    # current_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "    # save_path = os.path.join(current_dir, 'Models/' + model_name)\n",
    "    save_path = 'E:/Models/fcn/'\n",
    "    if os.path.exists(save_path) is False:\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    ################learning rate scheduler####################\n",
    "    def lr_scheduler(epoch, mode='power_decay'):\n",
    "        '''if lr_dict.has_key(epoch):\n",
    "            lr = lr_dict[epoch]\n",
    "            print 'lr: %f' % lr'''\n",
    "\n",
    "        if mode is 'power_decay':\n",
    "            # original lr scheduler\n",
    "            lr = lr_base * ((1 - float(epoch)/epochs) ** lr_power)\n",
    "        if mode is 'exp_decay':\n",
    "            # exponential decay\n",
    "            lr = (float(lr_base) ** float(lr_power)) ** float(epoch+1)\n",
    "        # adam default lr\n",
    "        if mode is 'adam':\n",
    "            lr = 0.001\n",
    "\n",
    "        if mode is 'progressive_drops':\n",
    "            # drops as progression proceeds, good for sgd\n",
    "            if epoch > 0.9 * epochs:\n",
    "                lr = 0.0001\n",
    "            elif epoch > 0.75 * epochs:\n",
    "                lr = 0.001\n",
    "            elif epoch > 0.5 * epochs:\n",
    "                lr = 0.01\n",
    "            else:\n",
    "                lr = 0.1\n",
    "\n",
    "        print('lr: %f' % lr)\n",
    "        return lr\n",
    "    \n",
    "    scheduler = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "    ####################### make model ########################\n",
    "    checkpoint_path = os.path.join(save_path, 'checkpoint_weights.hdf5')\n",
    "\n",
    "    model = globals()[model_name](weight_decay=weight_decay,\n",
    "                                  input_shape=input_shape,\n",
    "                                  batch_momentum=batchnorm_momentum,\n",
    "                                  classes=classes)\n",
    "    \n",
    "    \n",
    "    ####################### optimizer ########################\n",
    "    optimizer = SGD(lr=lr_base, momentum=0.9)\n",
    "    # optimizer = Nadam(lr=lr_base, beta_1 = 0.825, beta_2 = 0.99685)\n",
    "\n",
    "    model.compile(loss=loss_fn,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "    if resume_training:\n",
    "        model.load_weights(checkpoint_path, by_name=True)\n",
    "    model_path = os.path.join(save_path, \"model.json\")\n",
    "    # save model structure\n",
    "    f = open(model_path, 'w')\n",
    "    model_json = model.to_json()\n",
    "    f.write(model_json)\n",
    "    f.close\n",
    "    img_path = os.path.join(save_path, \"model.png\")\n",
    "    # #vis_util.plot(model, to_file=img_path, show_shapes=True)\n",
    "    model.summary()\n",
    "\n",
    "    # lr_reducer      = ReduceLROnPlateau(monitor=softmax_sparse_crossentropy_ignoring_last_label, factor=np.sqrt(0.1),\n",
    "    #                                     cooldown=0, patience=15, min_lr=0.5e-6)\n",
    "    # early_stopper   = EarlyStopping(monitor=sparse_accuracy_ignoring_last_label, min_delta=0.0001, patience=70)\n",
    "    # callbacks = [early_stopper, lr_reducer]\n",
    "    callbacks = [scheduler]\n",
    "\n",
    "    # ####################### tfboard ###########################\n",
    "    if K.backend() == 'tensorflow':\n",
    "        tensorboard = TensorBoard(log_dir=os.path.join(save_path, 'logs'), histogram_freq=10, write_graph=True)\n",
    "        callbacks.append(tensorboard)\n",
    "    # ################### checkpoint saver#######################\n",
    "    checkpoint = ModelCheckpoint(filepath=os.path.join(save_path, 'checkpoint_weights.hdf5'), save_weights_only=True)#.{epoch:d}\n",
    "    callbacks.append(checkpoint)\n",
    "    # set data generator and train\n",
    "    train_datagen = SegDataGenerator(zoom_range=[0.5, 2.0],\n",
    "                                     zoom_maintain_shape=True,\n",
    "                                     crop_mode='random',\n",
    "                                     crop_size=target_size,\n",
    "                                     # pad_size=(505, 505),\n",
    "                                     rotation_range=0.,\n",
    "                                     shear_range=0,\n",
    "                                     horizontal_flip=True,\n",
    "                                     channel_shift_range=20.,\n",
    "                                     fill_mode='constant',\n",
    "                                     label_cval=label_cval)\n",
    "    val_datagen = SegDataGenerator()\n",
    "\n",
    "    def get_file_len(file_path):\n",
    "        fp = open(file_path)\n",
    "        lines = fp.readlines()\n",
    "        fp.close()\n",
    "        return len(lines)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # from Keras documentation: Total number of steps (batches of samples) to yield from generator before declaring one epoch finished\n",
    "    # and starting the next epoch. It should typically be equal to the number of unique samples of your dataset divided by the batch size.\n",
    "    steps_per_epoch = int(np.ceil(get_file_len(train_file_path) / float(batch_size)))\n",
    "    history = model.fit_generator(\n",
    "        generator=train_datagen.flow_from_directory(\n",
    "            file_path=train_file_path,\n",
    "            data_dir=data_dir, data_suffix=data_suffix,\n",
    "            label_dir=label_dir, label_suffix=label_suffix,\n",
    "            classes=classes,\n",
    "            target_size=target_size, color_mode='rgb',\n",
    "            batch_size=batch_size, shuffle=True,\n",
    "            loss_shape=loss_shape,\n",
    "            ignore_label=ignore_label,\n",
    "            # save_to_dir='Images/'\n",
    "        ),\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        workers=4,\n",
    "        # validation_data=val_datagen.flow_from_directory(\n",
    "        #     file_path=val_file_path, data_dir=data_dir, data_suffix='.jpg',\n",
    "        #     label_dir=label_dir, label_suffix='.png',classes=classes,\n",
    "        #     target_size=target_size, color_mode='rgb',\n",
    "        #     batch_size=batch_size, shuffle=False\n",
    "        # ),\n",
    "        # nb_val_samples = 64\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "\n",
    "    model.save_weights(save_path+'/model.hdf5')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ae57a7fc494b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_name' is not defined"
     ]
    }
   ],
   "source": [
    "print(globals()[model_name])\n",
    "print(save_path)\n",
    "print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'AtrousFCN_Resnet50_16s'\n",
    "#model_name = 'Atrous_DenseNet'\n",
    "#model_name = 'DenseNet_FCN'\n",
    "model_name = 'FCN_Vgg16_32s'\n",
    "\n",
    "batch_size  = 16\n",
    "batchnorm_momentum = 0.95\n",
    "epochs      = 250\n",
    "lr_base     = 0.01 * (float(batch_size) / 16)\n",
    "lr_power    = 0.9\n",
    "resume_training = False\n",
    "if model_name is 'AtrousFCN_Resnet50_16s':\n",
    "    weight_decay = 0.0001/2\n",
    "else:\n",
    "    weight_decay = 1e-4\n",
    "    \n",
    "    \n",
    "target_size = (320,320)\n",
    "\n",
    "\n",
    "dataset     = 'VOC2012_BERKELEY'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heelo\n"
     ]
    }
   ],
   "source": [
    "if dataset == 'VOC2012_BERKELEY':\n",
    "    # pascal voc + berkeley semantic contours annotations\n",
    "    train_file_path = 'E:/MLDatasets/FCN/combined_imageset_train.txt'\n",
    "    #Data/VOClarge/VOC2012/ImageSets/Segmentation\n",
    "    \n",
    "    # train_file_path = os.path.expanduser('~/.keras/datasets/oneimage/train.txt') \n",
    "    #Data/VOClarge/VOC2012/ImageSets/Segmentation\n",
    "    print('heelo')\n",
    "    val_file_path   = 'E:/MLDatasets/FCN/combined_imageset_val.txt'\n",
    "    data_dir        = 'E:/MLDatasets/FCN/VOCdevkit/VOC2012/JPEGImages'\n",
    "    label_dir       = 'E:/MLDatasets/FCN/combined_annotations'\n",
    "    data_suffix='.jpg'\n",
    "    label_suffix='.png'\n",
    "    classes = 21\n",
    "\n",
    "if dataset == 'COCO':\n",
    "    # ###################### loss function & metric ########################\n",
    "    train_file_path = os.path.expanduser('~/.keras/datasets/VOC2012/VOCdevkit/VOC2012/ImageSets/Segmentation/train.txt') #Data/VOClarge/VOC2012/ImageSets/Segmentation\n",
    "    # train_file_path = os.path.expanduser('~/.keras/datasets/oneimage/train.txt') #Data/VOClarge/VOC2012/ImageSets/Segmentation\n",
    "    val_file_path   = os.path.expanduser('~/.keras/datasets/VOC2012/VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt')\n",
    "    data_dir        = os.path.expanduser('~/.keras/datasets/VOC2012/VOCdevkit/VOC2012/JPEGImages')\n",
    "    label_dir       = os.path.expanduser('~/.keras/datasets/VOC2012/VOCdevkit/VOC2012/SegmentationClass')\n",
    "    loss_fn = binary_crossentropy_with_logits\n",
    "    metrics = [binary_accuracy]\n",
    "    loss_shape = (target_size[0] * target_size[1] * classes,)\n",
    "    label_suffix = '.npy'\n",
    "    data_suffix='.jpg'\n",
    "    ignore_label = None\n",
    "    label_cval = 0\n",
    "\n",
    "\n",
    "# ###################### loss function & metric ########################\n",
    "if dataset == 'VOC2012' or dataset == 'VOC2012_BERKELEY':\n",
    "    loss_fn = softmax_sparse_crossentropy_ignoring_last_label\n",
    "    metrics = [sparse_accuracy_ignoring_last_label]\n",
    "    loss_shape = None\n",
    "    ignore_label = 255\n",
    "    label_cval = 255\n",
    "\n",
    "# Class weight is not yet supported for 3+ dimensional targets\n",
    "# class_weight = {i: 1 for i in range(classes)}\n",
    "# # The background class is much more common than all\n",
    "# # others, so give it less weight!\n",
    "# class_weight[0] = 0.1\n",
    "class_weight = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " classes : 21\n",
      " train file path  E:/MLDatasets/FCN/combined_imageset_train.txt\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 320, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 320, 320, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 320, 320, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 160, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 160, 160, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 160, 160, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 80, 80, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 80, 80, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 80, 80, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 80, 80, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 40, 40, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 40, 40, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 40, 40, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 40, 40, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "fc1 (Conv2D)                 (None, 10, 10, 4096)      102764544 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 10, 4096)      0         \n",
      "_________________________________________________________________\n",
      "fc2 (Conv2D)                 (None, 10, 10, 4096)      16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 10, 4096)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 21)        86037     \n",
      "_________________________________________________________________\n",
      "bilinear_up_sampling2d_1 (Bi (None, 320, 320, 21)      0         \n",
      "=================================================================\n",
      "Total params: 134,346,581\n",
      "Trainable params: 134,346,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "lr: 0.010000\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[7,7,512,4096]\n\t [[Node: training/SGD/mul_52 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](SGD/momentum/read, training/SGD/Variable_26/read)]]\n\t [[Node: metrics/sparse_accuracy_ignoring_last_label/Reshape/_277 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_459_metrics/sparse_accuracy_ignoring_last_label/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'training/SGD/mul_52', defined at:\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-d6a08b60298d>\", line 11, in <module>\n    label_suffix=label_suffix, ignore_label=ignore_label, label_cval=label_cval)\n  File \"<ipython-input-2-52e1a70fe3a4>\", line 148, in train\n    class_weight=class_weight\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 2026, in fit_generator\n    self._make_train_function()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 970, in _make_train_function\n    loss=self.total_loss)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\optimizers.py\", line 179, in get_updates\n    v = self.momentum * m - lr * g  # velocity\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 754, in _run_op\n    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 894, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1117, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2725, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[7,7,512,4096]\n\t [[Node: training/SGD/mul_52 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](SGD/momentum/read, training/SGD/Variable_26/read)]]\n\t [[Node: metrics/sparse_accuracy_ignoring_last_label/Reshape/_277 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_459_metrics/sparse_accuracy_ignoring_last_label/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[7,7,512,4096]\n\t [[Node: training/SGD/mul_52 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](SGD/momentum/read, training/SGD/Variable_26/read)]]\n\t [[Node: metrics/sparse_accuracy_ignoring_last_label/Reshape/_277 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_459_metrics/sparse_accuracy_ignoring_last_label/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d6a08b60298d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m       \u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchnorm_momentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatchnorm_momentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresume_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_training\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m       \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_suffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_suffix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m       label_suffix=label_suffix, ignore_label=ignore_label, label_cval=label_cval)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-52e1a70fe3a4>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(batch_size, epochs, lr_base, lr_power, weight_decay, classes, model_name, train_file_path, val_file_path, data_dir, label_dir, target_size, batchnorm_momentum, resume_training, class_weight, dataset, loss_fn, metrics, loss_shape, label_suffix, data_suffix, ignore_label, label_cval)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[1;31m# ),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;31m# nb_val_samples = 64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m     )\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2176\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1847\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1849\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[7,7,512,4096]\n\t [[Node: training/SGD/mul_52 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](SGD/momentum/read, training/SGD/Variable_26/read)]]\n\t [[Node: metrics/sparse_accuracy_ignoring_last_label/Reshape/_277 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_459_metrics/sparse_accuracy_ignoring_last_label/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'training/SGD/mul_52', defined at:\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-d6a08b60298d>\", line 11, in <module>\n    label_suffix=label_suffix, ignore_label=ignore_label, label_cval=label_cval)\n  File \"<ipython-input-2-52e1a70fe3a4>\", line 148, in train\n    class_weight=class_weight\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 2026, in fit_generator\n    self._make_train_function()\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 970, in _make_train_function\n    loss=self.total_loss)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\keras\\optimizers.py\", line 179, in get_updates\n    v = self.momentum * m - lr * g  # velocity\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 754, in _run_op\n    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 894, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1117, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2725, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"D:\\Program Files\\Anaconda3\\envs\\TF_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[7,7,512,4096]\n\t [[Node: training/SGD/mul_52 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](SGD/momentum/read, training/SGD/Variable_26/read)]]\n\t [[Node: metrics/sparse_accuracy_ignoring_last_label/Reshape/_277 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_459_metrics/sparse_accuracy_ignoring_last_label/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.95))\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "print(' classes :',classes)\n",
    "print(' train file path ', train_file_path)\n",
    "train(batch_size, epochs, lr_base, lr_power, weight_decay, classes, model_name, train_file_path, val_file_path,\n",
    "      data_dir, label_dir, target_size=target_size, batchnorm_momentum=batchnorm_momentum, resume_training=resume_training,\n",
    "      class_weight=class_weight, loss_fn=loss_fn, metrics=metrics, loss_shape=loss_shape, data_suffix=data_suffix,\n",
    "      label_suffix=label_suffix, ignore_label=ignore_label, label_cval=label_cval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(model.layers[0]._inbound_nodes[0].__dict__)\n",
    "pp.pprint(dir(model.layers[0]))\n",
    "pp.pprint(model.layers[0].get_config())\n",
    "# pp.pprint(model.layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # from Keras documentation: Total number of steps (batches of samples) to yield from generator before declaring one epoch finished\n",
    "    # and starting the next epoch. It should typically be equal to the number of unique samples of your dataset divided by the batch size.\n",
    "    steps_per_epoch = int(np.ceil(get_file_len(train_file_path) / float(batch_size)))\n",
    "'''\n",
    "    history = model.fit_generator(\n",
    "        generator=train_datagen.flow_from_directory(\n",
    "            file_path=train_file_path,\n",
    "            data_dir=data_dir, data_suffix=data_suffix,\n",
    "            label_dir=label_dir, label_suffix=label_suffix,\n",
    "            classes=classes,\n",
    "            target_size=target_size, color_mode='rgb',\n",
    "            batch_size=batch_size, shuffle=True,\n",
    "            loss_shape=loss_shape,\n",
    "            ignore_label=ignore_label,\n",
    "            # save_to_dir='Images/'\n",
    "        ),\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        workers=4,\n",
    "        # validation_data=val_datagen.flow_from_directory(\n",
    "        #     file_path=val_file_path, data_dir=data_dir, data_suffix='.jpg',\n",
    "        #     label_dir=label_dir, label_suffix='.png',classes=classes,\n",
    "        #     target_size=target_size, color_mode='rgb',\n",
    "        #     batch_size=batch_size, shuffle=False\n",
    "        # ),\n",
    "        # nb_val_samples = 64\n",
    "        class_weight=class_weight\n",
    "       )\n",
    "\n",
    "    model.save_weights(save_path+'/model.hdf5')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [TF_gpu]",
   "language": "python",
   "name": "Python [TF_gpu]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
